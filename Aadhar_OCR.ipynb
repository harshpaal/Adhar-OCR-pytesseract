{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Aadhar_OCR.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhS8Gq6vjB4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "@auther:  Harsh Pal\n",
        "@github: github.com/harshpaal\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSnXjV00Xbcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install tesseract-ocr\n",
        "!pip install tesseract\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import imutils\n",
        "import tesseract\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7pYwNS1gdxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/pytesseract'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf6PnasOe-dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Pillow\n",
        "!pip install pytesseract\n",
        "import pytesseract"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNXcTJT1hHbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7s3JnmtXbc8",
        "colab_type": "text"
      },
      "source": [
        "#### Function to crop the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8vwywMGXbc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_down_view(img, rect):\n",
        "    #Get All corner points of rect\n",
        "#     rect = np.zeros((4, 2), np.float32)\n",
        "    \n",
        "#     points_sum = points.sum(axis=1)\n",
        "#     points_diff = np.diff(points, axis=1)\n",
        "    \n",
        "#     rect[0] = points[np.argmin(points_sum)]\n",
        "#     rect[2] = points[np.argmax(points_sum)]\n",
        "    \n",
        "#     rect[1] = points[np.argmin(points_diff)]\n",
        "#     rect[3] = points[np.argmax(points_diff)]\n",
        "    \n",
        "    top_left, top_right = rect[0], rect[1]\n",
        "    bottom_left, bottom_right = rect[3], rect[2]\n",
        "    \n",
        "    width = max(\n",
        "        int(np.sqrt(((top_left[0] - top_right[0]) ** 2) + ((top_left[1] - top_right[1])**2))),\n",
        "        int(np.sqrt(((bottom_left[0] - bottom_right[0]) ** 2) + ((bottom_left[1] - bottom_right[1]) ** 2)))\n",
        "    )\n",
        "    \n",
        "    height = max(\n",
        "        int(np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))),\n",
        "        int(np.sqrt(((top_right[0] - bottom_right[0]) ** 2) + ((top_right[1] - bottom_right[1]) ** 2)))\n",
        "    )\n",
        "    \n",
        "    mat = np.array([\n",
        "        [0, 0],\n",
        "        [width-1, 0],\n",
        "        [width-1, height-1],\n",
        "        [0, height-1]\n",
        "    ], np.float32)\n",
        "    \n",
        "    M = cv2.getPerspectiveTransform(rect, mat)\n",
        "    changed_img = cv2.warpPerspective(img, M, (width, height))\n",
        "    \n",
        "    return changed_img"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkJ7JDM9XbdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cropped_image(img_1):\n",
        "    resized_ratio = img_1.shape[1] / 500\n",
        "    img = imutils.resize(img_1, width=500)\n",
        "\n",
        "    #convert to grey scale\n",
        "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_grey = cv2.GaussianBlur(img_grey, (5, 5), 0)\n",
        "\n",
        "    #Detect edges from image\n",
        "    img_edge = cv2.Canny(img_grey, 75, 150)\n",
        "    \n",
        "    contours = cv2.findContours(img_edge.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = imutils.grab_contours(contours)\n",
        "\n",
        "    #contours = sorted(contours, key = cv2.contourArea, reverse=True)[:5]\n",
        "\n",
        "    #Iterate over contours\n",
        "    (x, y, w, h) = cv2.boundingRect(contours[0])\n",
        "\n",
        "    max_area = w * h\n",
        "    cnt = contours[0]\n",
        "    \n",
        "    for c in contours:\n",
        "#     perimeter = cv2.arcLength(c, True)\n",
        "    \n",
        "#     approx = cv2.approxPolyDP(c, 0.02 * perimeter, True)\n",
        "#     print(len(approx))\n",
        "    \n",
        "#     if len(approx) == 4:\n",
        "#         target = approx\n",
        "#         break\n",
        "\n",
        "        (x_t, y_t, w_t, h_t) = cv2.boundingRect(c)\n",
        "\n",
        "        if (w_t * h_t) > max_area:\n",
        "            max_area = w_t * h_t\n",
        "            x, y, w, h = x_t, y_t, w_t, h_t\n",
        "            cnt = c\n",
        "            \n",
        "    boundary = np.array([\n",
        "    [x, y], \n",
        "    [x+w, y],\n",
        "    [x+w, y+h],\n",
        "    [x, y+h]\n",
        "    ], np.float32)\n",
        "    \n",
        "    boundary = boundary * resized_ratio\n",
        "    \n",
        "    top_view = get_top_down_view(img_1, boundary)\n",
        "    top_view = imutils.resize(top_view, width=500)\n",
        "\n",
        "    return top_view"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOJ7wHydXbdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_text(img):\n",
        "    text = pytesseract.image_to_string(img, lang='eng')\n",
        "    return text"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "datLd-AwXbdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_text_from_image(image):\n",
        "    \n",
        "    print('Start detecting contours...')\n",
        "    rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3))\n",
        "    sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    \n",
        "    gray  = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    dst = cv2.GaussianBlur(gray,(5,5),cv2.BORDER_DEFAULT)\n",
        "    blur = cv2.medianBlur(gray,5)\n",
        "    blur = cv2.morphologyEx(blur, cv2.MORPH_OPEN, sqKernel)\n",
        "\n",
        "    ret3, thresh3 = cv2.threshold(gray,100,255, cv2.THRESH_BINARY)\n",
        "    ret, thresh = cv2.threshold(gray,100,255, cv2.THRESH_BINARY_INV)\n",
        "    \n",
        "    tophat = cv2.morphologyEx(thresh, cv2.MORPH_TOPHAT, rectKernel)\n",
        "    gradX = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
        "    gradX = np.absolute(gradX)\n",
        "    (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
        "    gradX = (255 * ((gradX - minVal) / (maxVal - minVal)))\n",
        "    gradX = gradX.astype(\"uint8\")\n",
        "    gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)\n",
        "    thresh2 = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "    thresh2 = cv2.morphologyEx(thresh2, cv2.MORPH_CLOSE, sqKernel)\n",
        "    \n",
        "    cnts = cv2.findContours(thresh2.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    print('Contour detection ended....')\n",
        "    locs = []\n",
        "    \n",
        "    for c in cnts[0]:\n",
        "        # compute the bounding box of the contour, then use the\n",
        "        # bounding box coordinates to derive the aspect rati\n",
        "        (x, y, w, h) = cv2.boundingRect(c)\n",
        "        if h == 0:\n",
        "            h = 1\n",
        "        ar = float(w) / h\n",
        "\n",
        "        #print(x, y, w, h)\n",
        "        #locs.append((x, y, w, h))\n",
        "\n",
        "        # since credit cards used a fixed size fonts with 4 groups\n",
        "        # of 4 digits, we can prune potential contours based on the\n",
        "        # aspect ratio\n",
        "    #     if ar > 0 and ar < 24:\n",
        "    #         #cv2.rectangle(image, (x,y),(x+w,y+h),(255,0,0),1)\n",
        "    #         #locs.append((x, y, w, h))\n",
        "    #         # contours can further be pruned on minimum/maximum width\n",
        "    #         # and height\n",
        "    #         if (w > 0 and w < 500) and (h > 5 and h < 19):\n",
        "    #         # append the bounding box region of the digits group\n",
        "    #         # to our locations list\n",
        "        locs.append((x, y, w, h))\n",
        "        #cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
        "        \n",
        "    print(len(locs), 'contours found in image...')\n",
        "    \n",
        "    print('Starting recognition of text......')\n",
        "    \n",
        "    text_from_image = []\n",
        "    for loc in locs:\n",
        "    #cv2.rectangle(image, (loc[0], loc[1]), (loc[0]+loc[2], loc[1]+loc[3]), (0, 255, 0), 1)\n",
        "        part = image[max(0, loc[1]-2):min(image.shape[0], loc[1]+loc[3]+2), max(0, loc[0]-2):min(image.shape[1],loc[0]+loc[2]+2)]\n",
        "        text = get_text(part)\n",
        "        if len(text) > 0:\n",
        "            text_from_image.append(text)\n",
        "            \n",
        "    print('Text recognition ended....')\n",
        "            \n",
        "    return text_from_image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlE74fWDXbdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_face_from_image(frame):\n",
        "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    \n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,125), 2)\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = frame[y:y+h, x:x+w]\n",
        "        \n",
        "        return roi_color"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7G_RoKEXbdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread('img2.jpeg')\n",
        "img_1 = imutils.resize(img, width=500)\n",
        "cv2_imshow(img_1)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "top_view = get_cropped_image(img)\n",
        "cv2_imshow(top_view)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "text_from_image = get_text_from_image(top_view)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMUCB2yQXbdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(text_from_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlvZxXhgXbd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face = get_face_from_image('img2.jpeg')\n",
        "cv2.imshow('Face', face)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}